"""
Rules to polish a subcluster
"""

from Bio import SeqIO
import pandas, numpy

RACON_ITERS = config.get('racon_iters', 3)
MIN_Q = config.get('min_q', 9)

def get_polished_comparison_files(kind=None):
    """ return a list of output files for the polishing step for all subclusters
    if GROUP is set (config['group']), only that group of clusters is processed """
    logger.debug("Getting output files from polishing")

    out_fnames = ['medaka.v.drafts.gene.lengths',
                  'medaka.v.drafts.paf.agg']
    if kind == 'gene':
        out_fnames = out_fnames[:1]

    gr_cl_sc_s = [(group, cluster, subcluster)
                  for group, cluster in get_pre_filtered_clusters() \
                  for subcluster in get_pre_filtered_subclusters(group, cluster) ]
    logger.debug(f"Found {len(gr_cl_sc_s)} subclusters total")

    return [(SUBCLUSTER_DIR_TEMPLATE + "/" + fname).format(WORK_DIR=WORK_DIR, **locals()) \
            for group, cluster, subcluster in gr_cl_sc_s
            for fname in out_fnames
           ]

def comparison_inputs(wildcards, as_dict=False):
    " return a list or dict of faa files from polishing drafts "
    from snakemake.io import Namedlist
    input_dict = {'medaka': f'{wildcards.prefix}/medaka.faa'}
    for i in range(RACON_ITERS + 1):
        input_dict[f'draft_{i}'] = f'{wildcards.prefix}/draft.{i}.faa'
    return input_dict if as_dict else input_dict.values()

rule compare_genes:
    """ tabulate the number, mean length, and total AAs of predicted genes for each draft """
    input: comparison_inputs
    output: '{prefix}/medaka.v.drafts.gene.lengths'
    benchmark: '{prefix}/medaka.v.drafts.gene.lengths.time'
    run:
        data = []
        names = []
        for name, faa_file in comparison_inputs(wildcards, as_dict=True).items():
            lengths = []
            for gene in SeqIO.parse(faa_file, 'fasta'):
                _, start, end, _ = gene.description.split("#", 3)
                lengths.append(int(end) - int(start))
            if len(lengths) > 0:
                lengths = numpy.array(lengths)
                data.append(dict(mean=numpy.round(lengths.mean(),1),
                                 max=lengths.max(),
                                 min=lengths.min(),
                                 median=numpy.median(lengths),
                                 num=len(lengths),
                                 total=lengths.sum()
                                ))
            else:
                data.append({k:0 for k in
                ['mean','max','min','median','num','total']})
            names.append(name)
        stats = pandas.DataFrame(data, index=names)
        stats.sort_index().to_csv(str(output), sep='\t')            

rule agg_draft_hits:
    """ aggregate the minimap output by hit/query pairs to get a shorter summary table """
    input: '{prefix}/medaka.v.drafts.paf'
    output: '{prefix}/medaka.v.drafts.paf.agg'
    benchmark: '{prefix}/medaka.v.drafts.paf.agg.time'
    run: 
        from jme.jupy_tools.hit_tables import agg_hit_table, PAF
        agg_hit_table(str(input), format=PAF) \
                .to_csv(str(output), sep='\t', index=None)

rule compare_drafts:
    """ map polished seq agaisnt all the drafts """
    input: 
        final='{prefix}/medaka.fasta',
        drafts='{prefix}/drafts.fasta'
    output: '{prefix}/medaka.v.drafts.paf'
    benchmark: '{prefix}/medaka.v.drafts.paf.time'
    conda: '../conda/cluster.yaml'
    shell: 'minimap2 -x map-ont {input.drafts} {input.final} \
            > {output} \
            2> {output}.log'

rule collect_drafts:
    """ put all the drafts into a fasta file to compare with the final sequence """
    input: lambda w: [f"{w.prefix}/draft.{n}.fasta" for n in range(RACON_ITERS + 1)]
    output: '{prefix}/drafts.fasta'
    benchmark: '{prefix}/drafts.fasta.time'
    run:
        with open(str(output), 'wt') as fasta_out:
            for draft in input:
                for read in SeqIO.parse(str(draft), 'fasta'):
                    read.id = os.path.basename(draft)
                    fasta_out.write(read.format('fasta'))

rule minimap_4_reference:
    """ all v all to pick a ref read """
    input: '{prefix}/reads/subcluster.{subcluster}.fasta'
    output: '{prefix}/subcluster.{subcluster}/all.v.all.paf'
    benchmark: '{prefix}/subcluster.{subcluster}/all.v.all.paf.time'
    conda: '../conda/cluster.yaml'
    threads: 10
    shell: 'minimap2 -t {threads} -x ava-ont {input} {input} > {output}'

rule pick_ref_from_paf:
    """ pippcks a ref read and splits fasta into 2 (ref and others) """
    input:
        fasta='{prefix}/reads/subcluster.{subcluster}.fasta',
        paf='{prefix}/subcluster.{subcluster}/all.v.all.paf'
    output:
        ref='{prefix}/subcluster.{subcluster}/draft.0.fasta',
        others='{prefix}/subcluster.{subcluster}/other_reads.fasta'
    benchmark: '{prefix}/subcluster.{subcluster}/draft.0.fasta.time'
    conda: '../conda/cluster.yaml'
    script: '../scripts/pick_ref_from_paf.py'        

rule minimap_4_racon:
    input:
        draft=lambda w: f'{w.prefix}/subcluster.{w.subcluster}/draft.{int(w.racon_i) - 1}.fasta',
        reads='{prefix}/subcluster.{subcluster}/other_reads.fasta'
    output: "{prefix}/subcluster.{subcluster}/draft.{racon_i}.sam"
    benchmark: "{prefix}/subcluster.{subcluster}/draft.{racon_i}.sam.time"
    conda: '../conda/cluster.yaml'
    threads: 10
    shell: 'minimap2 -t {threads} -ax map-ont {input.draft} {input.reads} > {output}'
        
rule racon_iter:
    input:
        draft=lambda w: f'{w.prefix}/subcluster.{w.subcluster}/draft.{int(w.racon_i) - 1}.fasta',
        reads='{prefix}/subcluster.{subcluster}/other_reads.fasta',
        sam="{prefix}/subcluster.{subcluster}/draft.{racon_i}.sam"
    output: '{prefix}/subcluster.{subcluster}/draft.{racon_i}.fasta'
    benchmark: '{prefix}/subcluster.{subcluster}/draft.{racon_i}.fasta.time'
    conda: '../conda/polish.yaml'
    threads: 10
    shell: 'racon --include-unpolished \
                --quality-threshold={MIN_Q} \
                -t {threads} \
                {input.reads} {input.sam} {input.draft} \
                > {output} \
				2> {output}.log'

rule medaka:
    input:                                                                                       
        reads='{prefix}/subcluster.{subcluster}/other_reads.fasta',
        draft=lambda w: '{prefix}/subcluster.{subcluster}/draft.{racon_iters}.fasta' \
                            .format(racon_iters=RACON_ITERS, **w)
    output: '{prefix}/subcluster.{subcluster}/medaka.fasta'
    benchmark: '{prefix}/subcluster.{subcluster}/medaka.fasta.time'
    params:                                                                                      
        out_dir='{prefix}/subcluster.{subcluster}',
        model=config.get('MEDAKA_model', 'r941_min_high_g303')                                                          
    conda: '../conda/polish.yaml'
    threads: 10
    shell:                                                                                       
        """medaka_consensus -i {input.reads} -d {input.draft} \
            -o {params.out_dir} -t {threads} -m {params.model} \
			> {params.out_dir}.log 2>&1
           mv {params.out_dir}/consensus.fasta {output}"""
        
ruleorder: pick_ref_from_paf > racon_iter
