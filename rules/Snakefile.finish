SIGMA_CUTOFF = config.get('sigma_cutoff', 500)

def get_refining_mcls(w, as_dict=False):
    """ Find all the stats files for subcluster choosing (one for each kept
    cluster)

    Return a list if called from input, and dict for the python code
    """
    sc_mcls = \
        {cluster: f'{WORK_DIR}/refine_lastal/group.{group}/cluster.{cluster}/cluster.{cluster}.self.m8.gt{MFRAC_CUTOFF}.I{MCL_I}.mcl'
         for group, cluster in get_pre_filtered_clusters()}

    if as_dict:
        return sc_mcls
    return sc_mcls.values()


rule compile_report:
    """
    generate a short report with:
     * number of size windows
     * number of clusters (and # > 10 and number kept)
     * number of subclusters (and # > 10 and number kept)
     * number of polished seqs (with length stats)
     
    (fasta and faa are only inputs so that they get done, they are not needed
    for this)
    """
    input:
        pol_stats=f"{WORK_DIR}/final/polished.seqs.stats.tsv",
        fasta=f"{WORK_DIR}/final/polished.seqs.fasta",
        faa=f"{WORK_DIR}/final/polished.seqs.faa",
        mcl_stats=f'{WORK_DIR}/mcl_all/cluster_stats.tsv',
        sc_mcls=get_refining_mcls,
    params:
        min_cl_size=MIN_POL_READS + 1,
        sigma_cutoff=SIGMA_CUTOFF
    output:
        report=REPORT_FILE
    benchmark: REPORT_FILE + ".time"
    script: "../scripts/compile_report.py"


rule remove_fragments:
    """
    Remove sequences that are just short subsets of others in the results
    """
    input:
        frag_list=f"{WORK_DIR}/final/all/polished.fragmets.list",
        file=f"{WORK_DIR}/final/all/polished.seqs.{{ext}}",
    output:
        file=f"{WORK_DIR}/final/polished.seqs.{{ext}}",
    benchmark: f"{WORK_DIR}/final/polished.seqs.{{ext}}.time"
    wildcard_constraints:
        ext="(fasta|faa|stats.tsv)"
    conda: '../conda/cluster.yaml'
    params:
        screener=lambda w: "screen_list.py -f fasta" \
                           if w.ext.startswith('f') \
                           else "screen_table.py"
    shell:
        "{params.screener} -l {input.frag_list} {input.file} > {output.file}"

ruleorder: remove_fragments > prodigal

rule identify_fragemnts:
    """
    Identify sequences that are just short subsets of others in the results
    """
    input:
        paf=f"{WORK_DIR}/final/all/polished.v.self.paf",
    output:
        frag_list=f"{WORK_DIR}/final/all/polished.fragmets.list",
    params:
        format='PAF'
    conda: '../conda/cluster.yaml'
    script: "../scripts/identify_fragments.py"

rule polished_self_map:
    " Compare all polished seqs to all with minimap "
    input: f"{WORK_DIR}/final/all/polished.seqs.fasta"
    output: f"{WORK_DIR}/final/all/polished.v.self.paf"
    threads: MM_THREADS
    conda: '../conda/cluster.yaml'
    shell: "minimap2 -x ava-ont {input} {input} \
                > {output} \
                2> {output}.log"

rule collect_polished_seqs:
    """
    Collect polished sequences and stats
    """
    input: lambda w: get_polished_output_file_names(kind='genecomp')
    output:
        fasta=f"{WORK_DIR}/final/all/polished.seqs.fasta",
        faa=f"{WORK_DIR}/final/all/polished.seqs.faa",
        stats=f"{WORK_DIR}/final/all/polished.seqs.stats.tsv"
    benchmark: f"{WORK_DIR}/final/all/polished.seqs.stats.tsv.time"
    params:
        work_dir=WORK_DIR,
        name=NAME
    script: '../scripts/compile_polished_seqs.py'

# TODO
#  * identify and filter out sequences that are fragments of longer sequences
#  * annotate polished faa with PFAM
